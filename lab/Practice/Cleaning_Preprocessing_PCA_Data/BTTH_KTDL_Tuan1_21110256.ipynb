{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Bài tập Thực hành môn Khai phá Dữ liệu </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Họ và tên:** Huỳnh Nguyễn Thế Dân\n",
    "### **MSSV:** 21110256\n",
    "### **Lớp:** 21TTH1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cài đặt và thực thi mục 1 trên máy tính"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   First Name Last Name   Age Gender Department   Salary Date of Joining\n",
      "ID                                                                      \n",
      "1        John       Doe  25.0      M      Sales  50000.0      01/01/2020\n",
      "2        Jane     Smith  30.0      F  Marketing  60000.0      06/01/2018\n",
      "3         Bod   Johnson  45.0      M         HR  70000.0      09/01/2016\n",
      "4       Alice  Williams  33.0      F         IT  80000.0      02/01/2017\n",
      "5       James     Brown  27.0      M      Sales  55000.0      03/01/2019\n",
      "6       Sarah       Lee   NaN      F  Marketing  65000.0      12/01/2018\n",
      "7     Michael     Davis  39.0      M         HR      NaN      08/01/2015\n",
      "8       Susan    Miller  42.0      F         IT  90000.0      11/01/2014\n",
      "9       David    Wilson  28.0      M      Sales  60000.0      05/01/2020\n",
      "10      Emily     Brown  35.0      F  Marketing  55000.0      04/01/2017\n",
      "11       John       Doe  25.0      M      Sales  50000.0      01/01/2020\n",
      "12       John       Doe  25.0      M      Sales  50000.0      01/01/2020\n"
     ]
    }
   ],
   "source": [
    "# Load data from data.csv to DataFrame Pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df = pd.read_csv(\"data.csv\", delimiter=\",\")\n",
    "\n",
    "# Reset index\n",
    "df = df.set_index(\"ID\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Name         0\n",
      "Last Name          0\n",
      "Age                1\n",
      "Gender             0\n",
      "Department         0\n",
      "Salary             1\n",
      "Date of Joining    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check null values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN with mean values\n",
    "df[\"Age\"].fillna(df[\"Age\"].mean(), inplace=True)\n",
    "df[\"Salary\"].fillna(df[\"Salary\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Check duplicated values\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   First Name Last Name        Age Gender Department        Salary  \\\n",
      "ID                                                                   \n",
      "1        John       Doe  25.000000      M      Sales  50000.000000   \n",
      "2        Jane     Smith  30.000000      F  Marketing  60000.000000   \n",
      "3         Bod   Johnson  45.000000      M         HR  70000.000000   \n",
      "4       Alice  Williams  33.000000      F         IT  80000.000000   \n",
      "5       James     Brown  27.000000      M      Sales  55000.000000   \n",
      "6       Sarah       Lee  32.181818      F  Marketing  65000.000000   \n",
      "7     Michael     Davis  39.000000      M         HR  62272.727273   \n",
      "8       Susan    Miller  42.000000      F         IT  90000.000000   \n",
      "9       David    Wilson  28.000000      M      Sales  60000.000000   \n",
      "10      Emily     Brown  35.000000      F  Marketing  55000.000000   \n",
      "\n",
      "   Date of Joining  \n",
      "ID                  \n",
      "1       01/01/2020  \n",
      "2       06/01/2018  \n",
      "3       09/01/2016  \n",
      "4       02/01/2017  \n",
      "5       03/01/2019  \n",
      "6       12/01/2018  \n",
      "7       08/01/2015  \n",
      "8       11/01/2014  \n",
      "9       05/01/2020  \n",
      "10      04/01/2017  \n"
     ]
    }
   ],
   "source": [
    "# Remove duplicated values\n",
    "df = df.drop_duplicates()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   First Name Last Name        Age        Salary Date of Joining  Gender_F  \\\n",
      "ID                                                                           \n",
      "1        John       Doe  25.000000  50000.000000      01/01/2020     False   \n",
      "2        Jane     Smith  30.000000  60000.000000      06/01/2018      True   \n",
      "3         Bod   Johnson  45.000000  70000.000000      09/01/2016     False   \n",
      "4       Alice  Williams  33.000000  80000.000000      02/01/2017      True   \n",
      "5       James     Brown  27.000000  55000.000000      03/01/2019     False   \n",
      "6       Sarah       Lee  32.181818  65000.000000      12/01/2018      True   \n",
      "7     Michael     Davis  39.000000  62272.727273      08/01/2015     False   \n",
      "8       Susan    Miller  42.000000  90000.000000      11/01/2014      True   \n",
      "9       David    Wilson  28.000000  60000.000000      05/01/2020     False   \n",
      "10      Emily     Brown  35.000000  55000.000000      04/01/2017      True   \n",
      "\n",
      "    Gender_M  Department_HR  Department_IT  Department_Marketing  \\\n",
      "ID                                                                 \n",
      "1       True          False          False                 False   \n",
      "2      False          False          False                  True   \n",
      "3       True           True          False                 False   \n",
      "4      False          False           True                 False   \n",
      "5       True          False          False                 False   \n",
      "6      False          False          False                  True   \n",
      "7       True           True          False                 False   \n",
      "8      False          False           True                 False   \n",
      "9       True          False          False                 False   \n",
      "10     False          False          False                  True   \n",
      "\n",
      "    Department_Sales  \n",
      "ID                    \n",
      "1               True  \n",
      "2              False  \n",
      "3              False  \n",
      "4              False  \n",
      "5               True  \n",
      "6              False  \n",
      "7              False  \n",
      "8              False  \n",
      "9               True  \n",
      "10             False  \n"
     ]
    }
   ],
   "source": [
    "# Change categorical values to 0/1\n",
    "df = pd.get_dummies(df, columns=[\"Gender\", \"Department\"])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   First Name Last Name        Age        Salary  Gender_F  Gender_M  \\\n",
      "ID                                                                     \n",
      "1        John       Doe  25.000000  50000.000000     False      True   \n",
      "2        Jane     Smith  30.000000  60000.000000      True     False   \n",
      "3         Bod   Johnson  45.000000  70000.000000     False      True   \n",
      "4       Alice  Williams  33.000000  80000.000000      True     False   \n",
      "5       James     Brown  27.000000  55000.000000     False      True   \n",
      "6       Sarah       Lee  32.181818  65000.000000      True     False   \n",
      "7     Michael     Davis  39.000000  62272.727273     False      True   \n",
      "8       Susan    Miller  42.000000  90000.000000      True     False   \n",
      "9       David    Wilson  28.000000  60000.000000     False      True   \n",
      "10      Emily     Brown  35.000000  55000.000000      True     False   \n",
      "\n",
      "    Department_HR  Department_IT  Department_Marketing  Department_Sales  \\\n",
      "ID                                                                         \n",
      "1           False          False                 False              True   \n",
      "2           False          False                  True             False   \n",
      "3            True          False                 False             False   \n",
      "4           False           True                 False             False   \n",
      "5           False          False                 False              True   \n",
      "6           False          False                  True             False   \n",
      "7            True          False                 False             False   \n",
      "8           False           True                 False             False   \n",
      "9           False          False                 False              True   \n",
      "10          False          False                  True             False   \n",
      "\n",
      "    month day_of_week  \n",
      "ID                     \n",
      "1       1   Wednesday  \n",
      "2       6      Friday  \n",
      "3       9    Thursday  \n",
      "4       2   Wednesday  \n",
      "5       3      Friday  \n",
      "6      12    Saturday  \n",
      "7       8    Saturday  \n",
      "8      11    Saturday  \n",
      "9       5      Friday  \n",
      "10      4    Saturday  \n"
     ]
    }
   ],
   "source": [
    "# Processing Datetime\n",
    "\n",
    "## Change date column to datetime object \n",
    "df[\"Date of Joining\"] = pd.to_datetime(df[\"Date of Joining\"])\n",
    "\n",
    "## Extract month and day of week from date column\n",
    "df[\"month\"] = df[\"Date of Joining\"].dt.month\n",
    "df[\"day_of_week\"] = df[\"Date of Joining\"].dt.day_name()\n",
    "\n",
    "## Drop the original \"Date\" column\n",
    "df = df.drop(\"Date of Joining\", axis=1)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25.0 50000.0 False True False False False True 1]\n",
      " [30.0 60000.0 True False False False True False 6]\n",
      " [45.0 70000.0 False True True False False False 9]\n",
      " [33.0 80000.0 True False False True False False 2]\n",
      " [27.0 55000.0 False True False False False True 3]\n",
      " [32.18181818181818 65000.0 True False False False True False 12]\n",
      " [39.0 62272.72727272727 False True True False False False 8]\n",
      " [42.0 90000.0 True False False True False False 11]\n",
      " [28.0 60000.0 False True False False False True 5]\n",
      " [35.0 55000.0 True False False False True False 4]]\n"
     ]
    }
   ],
   "source": [
    "# Processing Outlier values, Standardization and Scale data\n",
    "\n",
    "df1 = df.drop([\"First Name\", \"Last Name\", \"day_of_week\"], axis=1)\n",
    "array = df1.values\n",
    "\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use RobustScaler() to drop outlier values\n",
    "scaler = preprocessing.RobustScaler()\n",
    "robust_df = scaler.fit_transform(array)\n",
    "robust_df = pd.DataFrame(robust_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardization data: \n",
      "            0         1    2    3    4    5         6         7         8\n",
      "ID                                                                      \n",
      "1  -1.369782 -1.264391 -1.0  1.0 -0.5 -0.5 -0.654654  1.527525 -1.420508\n",
      "2  -0.575077 -0.405854  1.0 -1.0 -0.5 -0.5  1.527525 -0.654654 -0.027853\n",
      "3   1.809037  0.452683 -1.0  1.0  2.0 -0.5 -0.654654 -0.654654  0.807740\n",
      "4  -0.098254  1.311220  1.0 -1.0 -0.5  2.0 -0.654654 -0.654654 -1.141977\n",
      "5  -1.051900 -0.835122 -1.0  1.0 -0.5 -0.5 -0.654654  1.527525 -0.863446\n",
      "6  -0.228297  0.023415  1.0 -1.0 -0.5 -0.5  1.527525 -0.654654  1.643333\n",
      "7   0.855391 -0.210732 -1.0  1.0  2.0 -0.5 -0.654654 -0.654654  0.529209\n",
      "8   1.332214  2.169757  1.0 -1.0 -0.5  2.0 -0.654654 -0.654654  1.364802\n",
      "9  -0.892959 -0.405854 -1.0  1.0 -0.5 -0.5 -0.654654  1.527525 -0.306384\n",
      "10  0.219627 -0.835122  1.0 -1.0 -0.5 -0.5  1.527525 -0.654654 -0.584915\n"
     ]
    }
   ],
   "source": [
    "### Standardization by Z-score\n",
    "scaler = preprocessing.StandardScaler()\n",
    "standard = scaler.fit_transform(array)\n",
    "standard_df = pd.DataFrame(standard,index = df.index)\n",
    "print(\"Standardization data: \\n\", standard_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling data: \n",
      "            0         1    2    3    4    5    6    7         8\n",
      "ID                                                            \n",
      "1   0.000000  0.000000  0.0  1.0  0.0  0.0  0.0  1.0  0.000000\n",
      "2   0.250000  0.250000  1.0  0.0  0.0  0.0  1.0  0.0  0.454545\n",
      "3   1.000000  0.500000  0.0  1.0  1.0  0.0  0.0  0.0  0.727273\n",
      "4   0.400000  0.750000  1.0  0.0  0.0  1.0  0.0  0.0  0.090909\n",
      "5   0.100000  0.125000  0.0  1.0  0.0  0.0  0.0  1.0  0.181818\n",
      "6   0.359091  0.375000  1.0  0.0  0.0  0.0  1.0  0.0  1.000000\n",
      "7   0.700000  0.306818  0.0  1.0  1.0  0.0  0.0  0.0  0.636364\n",
      "8   0.850000  1.000000  1.0  0.0  0.0  1.0  0.0  0.0  0.909091\n",
      "9   0.150000  0.250000  0.0  1.0  0.0  0.0  0.0  1.0  0.363636\n",
      "10  0.500000  0.125000  1.0  0.0  0.0  0.0  1.0  0.0  0.272727\n"
     ]
    }
   ],
   "source": [
    "### Scale data by Minmax method\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "minmax = scaler.fit_transform(array)\n",
    "minmax_df = pd.DataFrame(minmax,index = df.index)\n",
    "print(\"Scaling data: \\n\", minmax_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization first col by 10 equi-width ranges: \n",
      "            0         1    2    3    4    5         6         7         8  \\\n",
      "ID                                                                         \n",
      "1  -1.369782 -1.264391 -1.0  1.0 -0.5 -0.5 -0.654654  1.527525 -1.420508   \n",
      "2  -0.575077 -0.405854  1.0 -1.0 -0.5 -0.5  1.527525 -0.654654 -0.027853   \n",
      "3   1.809037  0.452683 -1.0  1.0  2.0 -0.5 -0.654654 -0.654654  0.807740   \n",
      "4  -0.098254  1.311220  1.0 -1.0 -0.5  2.0 -0.654654 -0.654654 -1.141977   \n",
      "5  -1.051900 -0.835122 -1.0  1.0 -0.5 -0.5 -0.654654  1.527525 -0.863446   \n",
      "6  -0.228297  0.023415  1.0 -1.0 -0.5 -0.5  1.527525 -0.654654  1.643333   \n",
      "7   0.855391 -0.210732 -1.0  1.0  2.0 -0.5 -0.654654 -0.654654  0.529209   \n",
      "8   1.332214  2.169757  1.0 -1.0 -0.5  2.0 -0.654654 -0.654654  1.364802   \n",
      "9  -0.892959 -0.405854 -1.0  1.0 -0.5 -0.5 -0.654654  1.527525 -0.306384   \n",
      "10  0.219627 -0.835122  1.0 -1.0 -0.5 -0.5  1.527525 -0.654654 -0.584915   \n",
      "\n",
      "   equi-width_column0  \n",
      "ID                     \n",
      "1    (-1.373, -1.052]  \n",
      "2    (-0.734, -0.416]  \n",
      "3      (1.491, 1.809]  \n",
      "4     (-0.0983, 0.22]  \n",
      "5    (-1.373, -1.052]  \n",
      "6   (-0.416, -0.0983]  \n",
      "7      (0.538, 0.855]  \n",
      "8      (1.173, 1.491]  \n",
      "9    (-1.052, -0.734]  \n",
      "10    (-0.0983, 0.22]  \n"
     ]
    }
   ],
   "source": [
    "# 10 equi-width ranges with first col of standard_df\n",
    "df2 = standard_df.copy()\n",
    "df2[\"equi-width_column0\"] = pd.cut(x = df2[0], bins = 10)\n",
    "print(\"Discretization first col by 10 equi-width ranges: \\n\", df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretization first col by 10 equi-depth ranges: \n",
      "            0         1    2    3    4    5         6         7         8  \\\n",
      "ID                                                                         \n",
      "1  -1.369782 -1.264391 -1.0  1.0 -0.5 -0.5 -0.654654  1.527525 -1.420508   \n",
      "2  -0.575077 -0.405854  1.0 -1.0 -0.5 -0.5  1.527525 -0.654654 -0.027853   \n",
      "3   1.809037  0.452683 -1.0  1.0  2.0 -0.5 -0.654654 -0.654654  0.807740   \n",
      "4  -0.098254  1.311220  1.0 -1.0 -0.5  2.0 -0.654654 -0.654654 -1.141977   \n",
      "5  -1.051900 -0.835122 -1.0  1.0 -0.5 -0.5 -0.654654  1.527525 -0.863446   \n",
      "6  -0.228297  0.023415  1.0 -1.0 -0.5 -0.5  1.527525 -0.654654  1.643333   \n",
      "7   0.855391 -0.210732 -1.0  1.0  2.0 -0.5 -0.654654 -0.654654  0.529209   \n",
      "8   1.332214  2.169757  1.0 -1.0 -0.5  2.0 -0.654654 -0.654654  1.364802   \n",
      "9  -0.892959 -0.405854 -1.0  1.0 -0.5 -0.5 -0.654654  1.527525 -0.306384   \n",
      "10  0.219627 -0.835122  1.0 -1.0 -0.5 -0.5  1.527525 -0.654654 -0.584915   \n",
      "\n",
      "   equi-depth_column0  \n",
      "ID                     \n",
      "1    (-1.371, -1.084]  \n",
      "2     (-0.67, -0.367]  \n",
      "3       (1.38, 1.809]  \n",
      "4    (-0.163, 0.0289]  \n",
      "5    (-1.084, -0.925]  \n",
      "6    (-0.367, -0.163]  \n",
      "7       (0.41, 0.951]  \n",
      "8       (0.951, 1.38]  \n",
      "9     (-0.925, -0.67]  \n",
      "10     (0.0289, 0.41]  \n"
     ]
    }
   ],
   "source": [
    "# 10 equi-depth ranges with first col of standard_df\n",
    "df3 = standard_df.copy()\n",
    "df3[\"equi-depth_column0\"] = pd.qcut(x = df3[0], q = 10)\n",
    "print(\"Discretization first col by 10 equi-depth ranges: \\n\", df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Làm tiếp những chổ chưa hoàn chỉnh ở mục 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3    4    5    6    7    8    9    ...  270   271   272  \\\n",
      "0     75    0  190   80   91  193  371  174  121  -16  ...  0.0   9.0  -0.9   \n",
      "1     56    1  165   64   81  174  401  149   39   25  ...  0.0   8.5   0.0   \n",
      "2     54    0  172   95  138  163  386  185  102   96  ...  0.0   9.5  -2.4   \n",
      "3     55    0  175   94  100  202  380  179  143   28  ...  0.0  12.2  -2.2   \n",
      "4     75    0  190   80   88  181  360  177  103  -16  ...  0.0  13.1  -3.6   \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
      "447   53    1  160   70   80  199  382  154  117  -37  ...  0.0   4.3  -5.0   \n",
      "448   37    0  190   85  100  137  361  201   73   86  ...  0.0  15.6  -1.6   \n",
      "449   36    0  166   68  108  176  365  194  116  -85  ...  0.0  16.3 -28.6   \n",
      "450   32    1  155   55   93  106  386  218   63   54  ... -0.4  12.0  -0.7   \n",
      "451   78    1  160   70   79  127  364  138   78   28  ...  0.0  10.4  -1.8   \n",
      "\n",
      "     273  274  275  276   277   278  279  \n",
      "0    0.0  0.0  0.9  2.9  23.3  49.4    8  \n",
      "1    0.0  0.0  0.2  2.1  20.4  38.8    6  \n",
      "2    0.0  0.0  0.3  3.4  12.3  49.0   10  \n",
      "3    0.0  0.0  0.4  2.6  34.6  61.6    1  \n",
      "4    0.0  0.0 -0.1  3.9  25.4  62.8    7  \n",
      "..   ...  ...  ...  ...   ...   ...  ...  \n",
      "447  0.0  0.0  0.7  0.6  -4.4  -0.5    1  \n",
      "448  0.0  0.0  0.4  2.4  38.0  62.4   10  \n",
      "449  0.0  0.0  1.5  1.0 -44.2 -33.2    2  \n",
      "450  0.0  0.0  0.5  2.4  25.0  46.6    1  \n",
      "451  0.0  0.0  0.5  1.6  21.3  32.8    1  \n",
      "\n",
      "[452 rows x 280 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "df = pd.read_csv(\"arrhythmia\\\\arrhythmia.data\", delimiter = \",\", header = None)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "275    0\n",
      "276    0\n",
      "277    0\n",
      "278    0\n",
      "279    0\n",
      "Length: 280, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check null values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375\n",
      "450\n",
      "399\n",
      "376\n",
      "385\n",
      "346\n",
      "320\n",
      "323\n",
      "362\n"
     ]
    }
   ],
   "source": [
    "# Check duplicate values\n",
    "for column in standard_df.columns:\n",
    "    print(df[column].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3    4    5    6    7    8    9    ...  270   271   272  \\\n",
      "0     75    0  190   80   91  193  371  174  121  -16  ...  0.0   9.0  -0.9   \n",
      "1     56    1  165   64   81  174  401  149   39   25  ...  0.0   8.5   0.0   \n",
      "2     54    0  172   95  138  163  386  185  102   96  ...  0.0   9.5  -2.4   \n",
      "3     55    0  175   94  100  202  380  179  143   28  ...  0.0  12.2  -2.2   \n",
      "4     75    0  190   80   88  181  360  177  103  -16  ...  0.0  13.1  -3.6   \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
      "447   53    1  160   70   80  199  382  154  117  -37  ...  0.0   4.3  -5.0   \n",
      "448   37    0  190   85  100  137  361  201   73   86  ...  0.0  15.6  -1.6   \n",
      "449   36    0  166   68  108  176  365  194  116  -85  ...  0.0  16.3 -28.6   \n",
      "450   32    1  155   55   93  106  386  218   63   54  ... -0.4  12.0  -0.7   \n",
      "451   78    1  160   70   79  127  364  138   78   28  ...  0.0  10.4  -1.8   \n",
      "\n",
      "     273  274  275  276   277   278  279  \n",
      "0    0.0  0.0  0.9  2.9  23.3  49.4    8  \n",
      "1    0.0  0.0  0.2  2.1  20.4  38.8    6  \n",
      "2    0.0  0.0  0.3  3.4  12.3  49.0   10  \n",
      "3    0.0  0.0  0.4  2.6  34.6  61.6    1  \n",
      "4    0.0  0.0 -0.1  3.9  25.4  62.8    7  \n",
      "..   ...  ...  ...  ...   ...   ...  ...  \n",
      "447  0.0  0.0  0.7  0.6  -4.4  -0.5    1  \n",
      "448  0.0  0.0  0.4  2.4  38.0  62.4   10  \n",
      "449  0.0  0.0  1.5  1.0 -44.2 -33.2    2  \n",
      "450  0.0  0.0  0.5  2.4  25.0  46.6    1  \n",
      "451  0.0  0.0  0.5  1.6  21.3  32.8    1  \n",
      "\n",
      "[452 rows x 280 columns]\n"
     ]
    }
   ],
   "source": [
    "# Replace '?' values with NaN\n",
    "df.replace('?', None, inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408\n"
     ]
    }
   ],
   "source": [
    "# Count the NaN values\n",
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert str to float\n",
    "df = df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1      2     3      4      5      6      7      8     9    ...  \\\n",
      "0    75.0  0.0  190.0  80.0   91.0  193.0  371.0  174.0  121.0 -16.0  ...   \n",
      "1    56.0  1.0  165.0  64.0   81.0  174.0  401.0  149.0   39.0  25.0  ...   \n",
      "2    54.0  0.0  172.0  95.0  138.0  163.0  386.0  185.0  102.0  96.0  ...   \n",
      "3    55.0  0.0  175.0  94.0  100.0  202.0  380.0  179.0  143.0  28.0  ...   \n",
      "4    75.0  0.0  190.0  80.0   88.0  181.0  360.0  177.0  103.0 -16.0  ...   \n",
      "..    ...  ...    ...   ...    ...    ...    ...    ...    ...   ...  ...   \n",
      "447  53.0  1.0  160.0  70.0   80.0  199.0  382.0  154.0  117.0 -37.0  ...   \n",
      "448  37.0  0.0  190.0  85.0  100.0  137.0  361.0  201.0   73.0  86.0  ...   \n",
      "449  36.0  0.0  166.0  68.0  108.0  176.0  365.0  194.0  116.0 -85.0  ...   \n",
      "450  32.0  1.0  155.0  55.0   93.0  106.0  386.0  218.0   63.0  54.0  ...   \n",
      "451  78.0  1.0  160.0  70.0   79.0  127.0  364.0  138.0   78.0  28.0  ...   \n",
      "\n",
      "     270   271   272  273  274  275  276   277   278   279  \n",
      "0    0.0   9.0  -0.9  0.0  0.0  0.9  2.9  23.3  49.4   8.0  \n",
      "1    0.0   8.5   0.0  0.0  0.0  0.2  2.1  20.4  38.8   6.0  \n",
      "2    0.0   9.5  -2.4  0.0  0.0  0.3  3.4  12.3  49.0  10.0  \n",
      "3    0.0  12.2  -2.2  0.0  0.0  0.4  2.6  34.6  61.6   1.0  \n",
      "4    0.0  13.1  -3.6  0.0  0.0 -0.1  3.9  25.4  62.8   7.0  \n",
      "..   ...   ...   ...  ...  ...  ...  ...   ...   ...   ...  \n",
      "447  0.0   4.3  -5.0  0.0  0.0  0.7  0.6  -4.4  -0.5   1.0  \n",
      "448  0.0  15.6  -1.6  0.0  0.0  0.4  2.4  38.0  62.4  10.0  \n",
      "449  0.0  16.3 -28.6  0.0  0.0  1.5  1.0 -44.2 -33.2   2.0  \n",
      "450 -0.4  12.0  -0.7  0.0  0.0  0.5  2.4  25.0  46.6   1.0  \n",
      "451  0.0  10.4  -1.8  0.0  0.0  0.5  1.6  21.3  32.8   1.0  \n",
      "\n",
      "[452 rows x 280 columns]\n"
     ]
    }
   ],
   "source": [
    "# Fill NaN with mean values\n",
    "df.fillna(df.mean(), inplace= True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 75.    0.  190.  ...  23.3  49.4   8. ]\n",
      " [ 56.    1.  165.  ...  20.4  38.8   6. ]\n",
      " [ 54.    0.  172.  ...  12.3  49.   10. ]\n",
      " ...\n",
      " [ 36.    0.  166.  ... -44.2 -33.2   2. ]\n",
      " [ 32.    1.  155.  ...  25.   46.6   1. ]\n",
      " [ 78.    1.  160.  ...  21.3  32.8   1. ]]\n"
     ]
    }
   ],
   "source": [
    "# Processing Outlier values, Standardization and Scale data\n",
    "array = df.values\n",
    "\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use RobustScaler() to drop outlier values\n",
    "scaler = preprocessing.RobustScaler()\n",
    "robust_df = scaler.fit_transform(array)\n",
    "robust_df = pd.DataFrame(robust_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardization data: \n",
      "           0         1         2         3         4         5         6    \\\n",
      "0    1.734439 -1.107520  0.641327  0.713814  0.135505  0.844945  0.113709   \n",
      "1    0.579312  0.902918 -0.031998 -0.251644 -0.516072  0.420769  1.013301   \n",
      "2    0.457720 -1.107520  0.156533  1.618932  3.197915  0.175193  0.563505   \n",
      "3    0.518516 -1.107520  0.237332  1.558590  0.721924  1.045871  0.383587   \n",
      "4    1.734439 -1.107520  0.641327  0.713814 -0.059968  0.577044 -0.216141   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "447  0.396924  0.902918 -0.166663  0.110403 -0.581229  0.978896  0.443560   \n",
      "448 -0.575815 -1.107520  0.641327  1.015520  0.721924 -0.405260 -0.186154   \n",
      "449 -0.636611 -1.107520 -0.005065 -0.010279  1.243185  0.465419 -0.066209   \n",
      "450 -0.879796  0.902918 -0.301328 -0.794714  0.265820 -1.097337  0.563505   \n",
      "451  1.916828  0.902918 -0.166663  0.110403 -0.646387 -0.628511 -0.096195   \n",
      "\n",
      "          7         8         9    ...       270       271        272  \\\n",
      "0    0.113809  1.201469 -1.094661  ...  0.508843 -0.013839   0.278621   \n",
      "1   -0.588564 -1.977064 -0.191203  ...  0.508843 -0.157972   0.728573   \n",
      "2    0.422853  0.464980  1.373324  ...  0.508843  0.130294  -0.471299   \n",
      "3    0.254284  2.054247 -0.125096  ...  0.508843  0.908612  -0.371310   \n",
      "4    0.198094  0.503742 -1.094661  ...  0.508843  1.168051  -1.071235   \n",
      "..        ...       ...       ...  ...       ...       ...        ...   \n",
      "447 -0.448089  1.046419 -1.557409  ...  0.508843 -1.368689  -1.771161   \n",
      "448  0.872372 -0.659136  1.152968  ...  0.508843  1.888716  -0.071342   \n",
      "449  0.675708  1.007656 -2.615116  ...  0.508843  2.090502 -13.569901   \n",
      "450  1.349985 -1.046762  0.447829  ... -0.220727  0.850959   0.378610   \n",
      "451 -0.897608 -0.465323 -0.125096  ...  0.508843  0.389733  -0.171331   \n",
      "\n",
      "          273  274       275       276       277       278       279  \n",
      "0   -0.079546  0.0  1.109553  1.177737  0.294603  1.078670  0.935771  \n",
      "1   -0.079546  0.0 -0.906889  0.616126  0.079613  0.504874  0.481455  \n",
      "2   -0.079546  0.0 -0.618826  1.528744 -0.520878  1.057018  1.390087  \n",
      "3   -0.079546  0.0 -0.330763  0.967133  1.132324  1.739077 -0.654336  \n",
      "4   -0.079546  0.0 -1.771079  1.879751  0.450286  1.804035  0.708613  \n",
      "..        ...  ...       ...       ...       ...       ...       ...  \n",
      "447 -0.079546  0.0  0.533427 -0.436895 -1.758926 -1.622502 -0.654336  \n",
      "448 -0.079546  0.0 -0.330763  0.826730  1.384382  1.782383  1.390087  \n",
      "449 -0.079546  0.0  2.837932 -0.156089 -4.709483 -3.392610 -0.427178  \n",
      "450 -0.079546  0.0 -0.042700  0.826730  0.420632  0.927101 -0.654336  \n",
      "451 -0.079546  0.0 -0.042700  0.265119  0.146334  0.180084 -0.654336  \n",
      "\n",
      "[452 rows x 280 columns]\n"
     ]
    }
   ],
   "source": [
    "### Standardization by Z-score\n",
    "scaler = preprocessing.StandardScaler()\n",
    "standard = scaler.fit_transform(array)\n",
    "standard_df = pd.DataFrame(standard,index = df.index)\n",
    "print(\"Standardization data: \\n\", standard_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling data: \n",
      "           0    1         2         3         4         5         6    \\\n",
      "0    0.903614  0.0  0.125926  0.435294  0.270677  0.368321  0.501805   \n",
      "1    0.674699  1.0  0.088889  0.341176  0.195489  0.332061  0.610108   \n",
      "2    0.650602  0.0  0.099259  0.523529  0.624060  0.311069  0.555957   \n",
      "3    0.662651  0.0  0.103704  0.517647  0.338346  0.385496  0.534296   \n",
      "4    0.903614  0.0  0.125926  0.435294  0.248120  0.345420  0.462094   \n",
      "..        ...  ...       ...       ...       ...       ...       ...   \n",
      "447  0.638554  1.0  0.081481  0.376471  0.187970  0.379771  0.541516   \n",
      "448  0.445783  0.0  0.125926  0.464706  0.338346  0.261450  0.465704   \n",
      "449  0.433735  0.0  0.090370  0.364706  0.398496  0.335878  0.480144   \n",
      "450  0.385542  1.0  0.074074  0.288235  0.285714  0.202290  0.555957   \n",
      "451  0.939759  1.0  0.081481  0.376471  0.180451  0.242366  0.476534   \n",
      "\n",
      "          7         8         9    ...       270       271       272  273  \\\n",
      "0    0.241758  0.590244  0.457478  ...  1.000000  0.381356  0.968531  0.0   \n",
      "1    0.150183  0.190244  0.577713  ...  1.000000  0.360169  1.000000  0.0   \n",
      "2    0.282051  0.497561  0.785924  ...  1.000000  0.402542  0.916084  0.0   \n",
      "3    0.260073  0.697561  0.586510  ...  1.000000  0.516949  0.923077  0.0   \n",
      "4    0.252747  0.502439  0.457478  ...  1.000000  0.555085  0.874126  0.0   \n",
      "..        ...       ...       ...  ...       ...       ...       ...  ...   \n",
      "447  0.168498  0.570732  0.395894  ...  1.000000  0.182203  0.825175  0.0   \n",
      "448  0.340659  0.356098  0.756598  ...  1.000000  0.661017  0.944056  0.0   \n",
      "449  0.315018  0.565854  0.255132  ...  1.000000  0.690678  0.000000  0.0   \n",
      "450  0.402930  0.307317  0.662757  ...  0.902439  0.508475  0.975524  0.0   \n",
      "451  0.109890  0.380488  0.586510  ...  1.000000  0.440678  0.937063  0.0   \n",
      "\n",
      "     274      275       276       277       278       279  \n",
      "0    0.0  0.53125  0.741667  0.507519  0.569579  0.466667  \n",
      "1    0.0  0.31250  0.675000  0.485714  0.500971  0.333333  \n",
      "2    0.0  0.34375  0.783333  0.424812  0.566990  0.600000  \n",
      "3    0.0  0.37500  0.716667  0.592481  0.648544  0.000000  \n",
      "4    0.0  0.21875  0.825000  0.523308  0.656311  0.400000  \n",
      "..   ...      ...       ...       ...       ...       ...  \n",
      "447  0.0  0.46875  0.550000  0.299248  0.246602  0.000000  \n",
      "448  0.0  0.37500  0.700000  0.618045  0.653722  0.600000  \n",
      "449  0.0  0.71875  0.583333  0.000000  0.034951  0.066667  \n",
      "450  0.0  0.40625  0.700000  0.520301  0.551456  0.000000  \n",
      "451  0.0  0.40625  0.633333  0.492481  0.462136  0.000000  \n",
      "\n",
      "[452 rows x 280 columns]\n"
     ]
    }
   ],
   "source": [
    "### Scale data by Minmax method\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "minmax = scaler.fit_transform(array)\n",
    "minmax_df = pd.DataFrame(minmax,index = df.index)\n",
    "print(\"Scaling data: \\n\", minmax_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0                1               2                3    \\\n",
      "0      (1.716, 2.221]  (-1.11, -0.906]   (0.17, 1.988]   (0.352, 1.378]   \n",
      "1      (0.202, 0.707]   (0.702, 0.903]  (-1.666, 0.17]  (-0.674, 0.352]   \n",
      "2      (0.202, 0.707]  (-1.11, -0.906]  (-1.666, 0.17]   (1.378, 2.403]   \n",
      "3      (0.202, 0.707]  (-1.11, -0.906]   (0.17, 1.988]   (1.378, 2.403]   \n",
      "4      (1.716, 2.221]  (-1.11, -0.906]   (0.17, 1.988]   (0.352, 1.378]   \n",
      "..                ...              ...             ...              ...   \n",
      "447    (0.202, 0.707]   (0.702, 0.903]  (-1.666, 0.17]  (-0.674, 0.352]   \n",
      "448  (-0.807, -0.302]  (-1.11, -0.906]   (0.17, 1.988]   (0.352, 1.378]   \n",
      "449  (-0.807, -0.302]  (-1.11, -0.906]  (-1.666, 0.17]  (-0.674, 0.352]   \n",
      "450  (-1.311, -0.807]   (0.702, 0.903]  (-1.666, 0.17]   (-1.7, -0.674]   \n",
      "451    (1.716, 2.221]   (0.702, 0.903]  (-1.666, 0.17]  (-0.674, 0.352]   \n",
      "\n",
      "                  4                 5                 6                 7    \\\n",
      "0      (-0.477, 0.39]   (0.0457, 1.216]   (0.0987, 0.929]   (-0.206, 0.561]   \n",
      "1    (-1.344, -0.477]   (0.0457, 1.216]     (0.929, 1.76]  (-0.973, -0.206]   \n",
      "2      (2.989, 3.856]   (0.0457, 1.216]   (0.0987, 0.929]   (-0.206, 0.561]   \n",
      "3       (0.39, 1.256]   (0.0457, 1.216]   (0.0987, 0.929]   (-0.206, 0.561]   \n",
      "4      (-0.477, 0.39]   (0.0457, 1.216]  (-0.732, 0.0987]   (-0.206, 0.561]   \n",
      "..                ...               ...               ...               ...   \n",
      "447  (-1.344, -0.477]   (0.0457, 1.216]   (0.0987, 0.929]  (-0.973, -0.206]   \n",
      "448     (0.39, 1.256]  (-1.124, 0.0457]  (-0.732, 0.0987]    (0.561, 1.328]   \n",
      "449     (0.39, 1.256]   (0.0457, 1.216]  (-0.732, 0.0987]    (0.561, 1.328]   \n",
      "450    (-0.477, 0.39]  (-1.124, 0.0457]   (0.0987, 0.929]    (1.328, 2.095]   \n",
      "451  (-1.344, -0.477]  (-1.124, 0.0457]  (-0.732, 0.0987]  (-0.973, -0.206]   \n",
      "\n",
      "                 8                  9    ...              270  \\\n",
      "0     (0.484, 1.279]   (-1.527, -0.775]  ...  (-0.239, 0.509]   \n",
      "1     (-2.694, -1.9]  (-0.775, -0.0237]  ...  (-0.239, 0.509]   \n",
      "2     (-0.31, 0.484]     (0.728, 1.479]  ...  (-0.239, 0.509]   \n",
      "3     (1.279, 2.074]  (-0.775, -0.0237]  ...  (-0.239, 0.509]   \n",
      "4     (0.484, 1.279]   (-1.527, -0.775]  ...  (-0.239, 0.509]   \n",
      "..               ...                ...  ...              ...   \n",
      "447   (0.484, 1.279]   (-2.278, -1.527]  ...  (-0.239, 0.509]   \n",
      "448  (-1.105, -0.31]     (0.728, 1.479]  ...  (-0.239, 0.509]   \n",
      "449   (0.484, 1.279]   (-3.029, -2.278]  ...  (-0.239, 0.509]   \n",
      "450  (-1.105, -0.31]   (-0.0237, 0.728]  ...  (-0.239, 0.509]   \n",
      "451  (-1.105, -0.31]  (-0.775, -0.0237]  ...  (-0.239, 0.509]   \n",
      "\n",
      "                  271                272               273             274  \\\n",
      "0     (-0.567, 0.113]    (-0.701, 0.729]  (-0.0955, 1.518]  (-0.0002, 0.0]   \n",
      "1     (-0.567, 0.113]    (-0.701, 0.729]  (-0.0955, 1.518]  (-0.0002, 0.0]   \n",
      "2      (0.113, 0.793]    (-0.701, 0.729]  (-0.0955, 1.518]  (-0.0002, 0.0]   \n",
      "3      (0.793, 1.474]    (-0.701, 0.729]  (-0.0955, 1.518]  (-0.0002, 0.0]   \n",
      "4      (0.793, 1.474]   (-2.131, -0.701]  (-0.0955, 1.518]  (-0.0002, 0.0]   \n",
      "..                ...                ...               ...             ...   \n",
      "447  (-1.928, -1.248]   (-2.131, -0.701]  (-0.0955, 1.518]  (-0.0002, 0.0]   \n",
      "448    (1.474, 2.154]    (-0.701, 0.729]  (-0.0955, 1.518]  (-0.0002, 0.0]   \n",
      "449    (1.474, 2.154]  (-13.584, -12.14]  (-0.0955, 1.518]  (-0.0002, 0.0]   \n",
      "450    (0.793, 1.474]    (-0.701, 0.729]  (-0.0955, 1.518]  (-0.0002, 0.0]   \n",
      "451    (0.113, 0.793]    (-0.701, 0.729]  (-0.0955, 1.518]  (-0.0002, 0.0]   \n",
      "\n",
      "                  275                276               277               278  \\\n",
      "0      (0.821, 1.743]     (0.827, 1.669]     (0.22, 1.206]    (0.497, 1.333]   \n",
      "1      (-1.022, -0.1]   (-0.0157, 0.827]    (-0.766, 0.22]    (0.497, 1.333]   \n",
      "2      (-1.022, -0.1]     (0.827, 1.669]    (-0.766, 0.22]    (0.497, 1.333]   \n",
      "3      (-1.022, -0.1]     (0.827, 1.669]     (0.22, 1.206]    (1.333, 2.169]   \n",
      "4    (-1.944, -1.022]     (1.669, 2.512]     (0.22, 1.206]    (1.333, 2.169]   \n",
      "..                ...                ...               ...               ...   \n",
      "447     (-0.1, 0.821]  (-0.858, -0.0157]  (-2.738, -1.752]  (-2.012, -1.176]   \n",
      "448    (-1.022, -0.1]   (-0.0157, 0.827]    (1.206, 2.192]    (1.333, 2.169]   \n",
      "449    (2.665, 3.587]  (-0.858, -0.0157]  (-4.719, -3.723]  (-3.693, -2.849]   \n",
      "450     (-0.1, 0.821]   (-0.0157, 0.827]     (0.22, 1.206]    (0.497, 1.333]   \n",
      "451     (-0.1, 0.821]   (-0.0157, 0.827]    (-0.766, 0.22]    (-0.34, 0.497]   \n",
      "\n",
      "                  279  \n",
      "0      (0.709, 1.049]  \n",
      "1      (0.368, 0.709]  \n",
      "2       (1.39, 1.731]  \n",
      "3    (-0.658, -0.314]  \n",
      "4      (0.368, 0.709]  \n",
      "..                ...  \n",
      "447  (-0.658, -0.314]  \n",
      "448     (1.39, 1.731]  \n",
      "449  (-0.658, -0.314]  \n",
      "450  (-0.658, -0.314]  \n",
      "451  (-0.658, -0.314]  \n",
      "\n",
      "[452 rows x 280 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a data frame by 10 equi-width with col of standard_df\n",
    "df_ranges1 = standard_df.copy()\n",
    "for column in standard_df.columns:\n",
    "    df_ranges1[column] = pd.cut(df_ranges1[column], bins = 10)\n",
    "\n",
    "print(df_ranges1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a data frame by 10 equi-depth with col of standard_df\n",
    "# df_ranges2 = standard_df.copy()\n",
    "# for column in standard_df.columns:\n",
    "#     df_ranges2[column] = pd.qcut(df_ranges2[column], q = 10)\n",
    "\n",
    "# print(df_ranges2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sử dụng mục 1 để làm sạch dữ liệu và tiền xử lý dữ liệu, và sử dụng PCA trong thư viện sklearn để làm mục 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          MUSK-188   188_1+1  42  -198  -109  -75  -117   11   23  -88  ...  \\\n",
      "0         MUSK-188   188_1+2  42  -191  -142  -65  -117   55   49 -170  ...   \n",
      "1         MUSK-188   188_1+3  42  -191  -142  -75  -117   11   49 -161  ...   \n",
      "2         MUSK-188   188_1+4  42  -198  -110  -65  -117   55   23  -95  ...   \n",
      "3         MUSK-190   190_1+1  42  -198  -102  -75  -117   10   24  -87  ...   \n",
      "4         MUSK-190   190_1+2  42  -191  -142  -65  -117   55   49 -170  ...   \n",
      "..             ...       ...  ..   ...   ...  ...   ...  ...  ...  ...  ...   \n",
      "470  NON-MUSK-jp13  jp13_1+4  49  -199  -161   29   -95  -86  -48    2  ...   \n",
      "471  NON-MUSK-jp13  jp13_2+1  38  -123  -139   30  -117  -88  214  -13  ...   \n",
      "472  NON-MUSK-jp13  jp13_2+2  43  -102   -20 -101  -116  200 -166   66  ...   \n",
      "473  NON-MUSK-jp13  jp13_2+3  39   -58    27   31  -117  -92   85   21  ...   \n",
      "474  NON-MUSK-jp13  jp13_2+4  52  -121   -24 -104  -116  195 -162   76  ...   \n",
      "\n",
      "     -74  -129  -120.2  -38.1   30  48.1  -37.2  6.1  30.1   1.  \n",
      "0   -302    60    -120    -39   31    48    -37    5    30  1.0  \n",
      "1    -73  -127    -120    -38   30    48    -37    5    31  1.0  \n",
      "2   -302    60    -120    -39   30    48    -37    6    30  1.0  \n",
      "3    -73  -127      51    128  144    43    -30   14    26  1.0  \n",
      "4   -300    61      51    127  143    42    -31   14    26  1.0  \n",
      "..   ...   ...     ...    ...  ...   ...    ...  ...   ...  ...  \n",
      "470 -246  -209      33    152  134    47    -43  -15   -10  0.0  \n",
      "471 -226  -210      20     55  119    79    -28    4    74  0.0  \n",
      "472   32   136     -15    143  121    55    -37  -19   -36  0.0  \n",
      "473 -232  -206      13     45  116    79    -28    3    74  0.0  \n",
      "474   34   133     -20    -46   95    98    -14   12    96  0.0  \n",
      "\n",
      "[475 rows x 169 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load data from data.csv to DataFrame Pandas\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv(\"musk+version+1\\\\clean1.data\\\\clean1.data\", delimiter=\",\")\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
