{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Bài tập Thực hành môn Khai phá Dữ liệu </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Họ và tên:** Huỳnh Nguyễn Thế Dân\n",
    "### **MSSV:** 21110256\n",
    "### **Lớp:** 21TTH1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cài đặt và thực thi mục 1 trên máy tính"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# Đọc dữ liệu từ tệp arrhythmia.data\n",
    "df = pd.read_csv(\"arrhythmia\\\\arrhythmia.data\", delimiter=\",\", header=None)\n",
    "\n",
    "# Hiển thị DataFrame\n",
    "display(df)\n",
    "\n",
    "# Kiểm tra giá trị null\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Điền giá trị NaN bằng giá trị trung bình\n",
    "df[\"Age\"].fillna(df[\"Age\"].mean(), inplace=True)\n",
    "df[\"Salary\"].fillna(df[\"Salary\"].mean(), inplace=True)\n",
    "\n",
    "# Kiểm tra giá trị trùng lặp\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "# Loại bỏ các giá trị trùng lặp\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Hiển thị DataFrame sau khi loại bỏ giá trị trùng lặp\n",
    "display(df)\n",
    "\n",
    "# Chuyển các giá trị hạng mục thành 0/1\n",
    "df = pd.get_dummies(df, columns=[\"Gender\", \"Department\"])\n",
    "\n",
    "# Hiển thị DataFrame sau khi chuyển đổi\n",
    "display(df)\n",
    "\n",
    "# Xử lý dữ liệu ngày tháng\n",
    "\n",
    "## Chuyển cột ngày tháng thành đối tượng datetime\n",
    "df[\"Date of Joining\"] = pd.to_datetime(df[\"Date of Joining\"])\n",
    "\n",
    "## Trích xuất tháng và ngày trong tuần từ cột ngày tháng\n",
    "df[\"month\"] = df[\"Date of Joining\"].dt.month\n",
    "df[\"day_of_week\"] = df[\"Date of Joining\"].dt.day_name()\n",
    "\n",
    "## Loại bỏ cột gốc \"Date\"\n",
    "df = df.drop(\"Date of Joining\", axis=1)\n",
    "\n",
    "# Hiển thị DataFrame sau khi xử lý dữ liệu ngày tháng\n",
    "display(df)\n",
    "\n",
    "# Xử lý các giá trị ngoại lai, chuẩn hóa và tỉ lệ dữ liệu\n",
    "\n",
    "df1 = df.drop([\"First Name\", \"Last Name\", \"day_of_week\"], axis=1)\n",
    "array = df1.values\n",
    "\n",
    "### Sử dụng RobustScaler() để loại bỏ các giá trị ngoại lai\n",
    "scaler = preprocessing.RobustScaler()\n",
    "robust_df = scaler.fit_transform(array)\n",
    "robust_df = pd.DataFrame(robust_df)\n",
    "\n",
    "### Chuẩn hóa theo Z-score\n",
    "scaler = preprocessing.StandardScaler()\n",
    "standard = scaler.fit_transform(array)\n",
    "standard_df = pd.DataFrame(standard, index=df.index)\n",
    "\n",
    "print(\"Dữ liệu chuẩn hóa theo Z-score: \\n\", standard_df)\n",
    "\n",
    "### Tỉ lệ dữ liệu theo phương pháp Minmax\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "minmax = scaler.fit_transform(array)\n",
    "minmax_df = pd.DataFrame(minmax, index=df.index)\n",
    "\n",
    "print(\"Dữ liệu tỉ lệ: \\n\", minmax_df)\n",
    "\n",
    "# 10 phạm vi equi-width với cột đầu tiên của standard_df\n",
    "df2 = standard_df.copy()\n",
    "df2[\"equi-width_column0\"] = pd.cut(x=df2[0], bins=10)\n",
    "print(\"Phân loại cột đầu tiên thành 10 phạm vi equi-width: \\n\", df2)\n",
    "\n",
    "# 10 phạm vi equi-depth với cột đầu tiên của standard_df\n",
    "df3 = standard_df.copy()\n",
    "df3[\"equi-depth_column0\"] = pd.qcut(x=df3[0], q=10)\n",
    "print(\"Phân loại cột đầu tiên thành 10 phạm vi equi-depth: \\n\", df3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đoạn mã trên thực hiện một loạt các thao tác xử lý dữ liệu, bao gồm điền giá trị trống, loại bỏ giá trị trùng lặp, chuyển đổi giá trị hạng mục thành biến giả (dummy variables), xử lý dữ liệu ngày tháng, xử lý các giá trị ngoại lai, chuẩn hóa và tỉ lệ dữ liệu, và phân loại dữ liệu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Làm tiếp những chỗ chưa hoàn chỉnh ở mục 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# Đọc dữ liệu từ tệp arrhythmia.data\n",
    "df = pd.read_csv(\"arrhythmia\\\\arrhythmia.data\", delimiter=\",\", header=None)\n",
    "\n",
    "# Hiển thị DataFrame\n",
    "display(df)\n",
    "\n",
    "# Kiểm tra giá trị null\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Kiểm tra giá trị trùng lặp cho từng cột\n",
    "for column in df.columns:\n",
    "    print(df[column].duplicated().sum())\n",
    "\n",
    "# Đếm số giá trị NaN\n",
    "print(df.isnull().sum().sum())\n",
    "\n",
    "# Chuyển đổi từ kiểu dữ liệu chuỗi sang kiểu dữ liệu số thực\n",
    "df = df.astype(float)\n",
    "\n",
    "# Điền giá trị NaN bằng giá trị trung bình của từng cột\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Xử lý các giá trị ngoại lai, chuẩn hóa và tỉ lệ dữ liệu\n",
    "array = df.values\n",
    "\n",
    "### Sử dụng RobustScaler() để loại bỏ các giá trị ngoại lai\n",
    "scaler = preprocessing.RobustScaler()\n",
    "robust_df = scaler.fit_transform(array)\n",
    "robust_df = pd.DataFrame(robust_df)\n",
    "\n",
    "### Chuẩn hóa theo Z-score\n",
    "scaler = preprocessing.StandardScaler()\n",
    "standard = scaler.fit_transform(array)\n",
    "standard_df = pd.DataFrame(standard, index=df.index)\n",
    "print(\"Dữ liệu chuẩn hóa theo Z-score: \\n\", standard_df)\n",
    "\n",
    "### Tỉ lệ dữ liệu theo phương pháp Minmax\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "minmax = scaler.fit_transform(array)\n",
    "minmax_df = pd.DataFrame(minmax, index=df.index)\n",
    "print(\"Dữ liệu tỉ lệ: \\n\", minmax_df)\n",
    "\n",
    "# Tạo một DataFrame với 10 phạm vi equi-width cho mỗi cột của standard_df\n",
    "df_ranges1 = standard_df.copy()\n",
    "for column in standard_df.columns:\n",
    "    df_ranges1[column] = pd.cut(df_ranges1[column], bins=10)\n",
    "\n",
    "display(df_ranges1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đoạn mã trên thực hiện một loạt các thao tác xử lý dữ liệu, bao gồm kiểm tra giá trị null, kiểm tra giá trị trùng lặp, chuyển đổi kiểu dữ liệu, xử lý giá trị null bằng cách điền giá trị trung bình, xử lý các giá trị ngoại lai, chuẩn hóa và tỉ lệ dữ liệu, và tạo DataFrame mới với các phạm vi equi-width cho dữ liệu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sử dụng mục 1 để làm sạch dữ liệu và tiền xử lý dữ liệu, và sử dụng PCA trong thư viện sklearn để làm mục 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Load data from data.csv to DataFrame Pandas\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Đọc dữ liệu từ tệp clean1.data\n",
    "df = pd.read_csv(\"musk+version+1\\\\clean1.data\\\\clean1.data\", delimiter=\",\", header=None)\n",
    "\n",
    "# Hiển thị DataFrame\n",
    "display(df)\n",
    "\n",
    "# Tạo một bản sao của DataFrame cho quá trình tiền xử lý\n",
    "preprocessing_df = df.copy()\n",
    "\n",
    "# Loại bỏ cột 0 và cột 1\n",
    "preprocessing_df.drop(columns=[0], inplace=True)\n",
    "preprocessing_df.drop(columns=[1], inplace=True)\n",
    "\n",
    "# Hiển thị DataFrame sau khi loại bỏ cột\n",
    "preprocessing_df\n",
    "\n",
    "# Kiểm tra giá trị null\n",
    "print(preprocessing_df.isnull().sum())\n",
    "\n",
    "# Kiểm tra giá trị trùng lặp\n",
    "print(preprocessing_df.duplicated().sum())\n",
    "\n",
    "# Chuyển DataFrame thành mảng numpy\n",
    "preprocessing_array = preprocessing_df.values\n",
    "\n",
    "print(preprocessing_array)\n",
    "\n",
    "### Chuẩn hóa theo Z-score\n",
    "scaler = preprocessing.StandardScaler()\n",
    "standard = scaler.fit_transform(preprocessing_array)\n",
    "standard_df = pd.DataFrame(standard,index = df.index)\n",
    "print(\"Dữ liệu chuẩn hóa theo Z-score: \\n\", standard_df)\n",
    "\n",
    "# Tính ma trận hiệp phương sai\n",
    "cov_matrix = standard_df.cov()\n",
    "\n",
    "# Tính giá trị riêng và vector riêng\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Vẽ biểu đồ Scree\n",
    "plt.plot(range(1,168),eigenvalues)\n",
    "plt.title(\"Scree plot\")\n",
    "plt.show()\n",
    "\n",
    "# Sử dụng PCA để giảm chiều dữ liệu xuống còn 50 thành phần\n",
    "pca = PCA(n_components=50)\n",
    "tranformed_data = pca.fit_transform(standard_df)\n",
    "\n",
    "# Tạo DataFrame mới từ dữ liệu sau khi giảm chiều\n",
    "df_PCA = pd.DataFrame(tranformed_data)\n",
    "\n",
    "# Hiển thị DataFrame mới\n",
    "display(df_PCA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Đoạn mã trên thực hiện các thao tác như sau:\n",
    "\n",
    "1. Đọc dữ liệu từ tệp `clean1.data` và hiển thị DataFrame.\n",
    "2. Tiền xử lý dữ liệu bằng cách loại bỏ các cột không cần thiết.\n",
    "3. Kiểm tra giá trị null và giá trị trùng lặp.\n",
    "4. Chuẩn hóa dữ liệu theo Z-score.\n",
    "5. Tính toán ma trận hiệp phương sai và các giá trị riêng, sau đó vẽ biểu đồ Scree.\n",
    "6. Sử dụng PCA để giảm chiều dữ liệu xuống còn 50 thành phần và hiển thị DataFrame mới sau khi giảm chiều.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
